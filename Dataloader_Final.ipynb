{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbb4237-d4f9-43cc-ba29-af8c3ffea8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Dataloader ###\n",
    "# From PDF to CSV\n",
    "# Here, the data is extracted from the PDF files and merged with the Schultz main data before being stored as a CSV file. \n",
    "# The preparation of the main data is done in a separate script.\n",
    "# This process is done separately for each commune before being merged together.\n",
    "# Note: It's not possible to run the scripts since the PDF files are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e110f9ce-5156-42ec-bd64-6d430787c2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd          # To handle and manipulate dataframes\n",
    "import os                    # To interact with the operating system\n",
    "import pdfplumber            # To extract text from PDF files\n",
    "import re                    # To use regular expressions\n",
    "from tqdm import tqdm        # To display progress bars for loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20648602-2f32-4f23-9bf6-cb4197ab700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Data Loader #\n",
    "\n",
    "# The folder containing the PDF files\n",
    "pdf_folder = 'C:\\\\Users....'\n",
    "\n",
    "# List to store data extracted from the PDF files\n",
    "data = []\n",
    "\n",
    "# Retrieve a list of all files in pdf_folder, including subdirectories\n",
    "all_files = [os.path.join(root, filename) for root, dirs, files in os.walk(pdf_folder) for filename in files]\n",
    "\n",
    "# Use tqdm to display a progress bar\n",
    "for pdf_path in tqdm(all_files, desc=\"Processing PDF files\"):\n",
    "    try:\n",
    "        # Open each file as a PDF\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Loop through all pages in the PDF file\n",
    "            for page in pdf.pages:\n",
    "                # Extract text from the current page\n",
    "                text = page.extract_text()\n",
    "                \n",
    "                # Add the data to the list\n",
    "                data.append({'PDF Filename': os.path.basename(pdf_path), 'Text': text})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {os.path.basename(pdf_path)}: {e}\")\n",
    "\n",
    "# The 'data' list now contains information from all successfully processed PDF files, except those that caused errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c0e66-b23d-47c8-887c-d57c5416c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove duplicate rows based on the 'PDF Filename' column\n",
    "df = df.drop_duplicates(subset=['PDF Filename'])\n",
    "\n",
    "# Retrieve the text content of the first two unique PDF files\n",
    "file1_text_1 = df.iloc[0]['Text']\n",
    "file1_text_2 = df.iloc[1]['Text']\n",
    "\n",
    "# Identify differences between the two text strings by comparing characters at each index\n",
    "difference = [i for i in range(min(len(file1_text_1), len(file1_text_2))) if file1_text_1[i] != file1_text_2[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412f7377-0fb8-4a1f-902b-f179db70037d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selection of variables from all the information forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad596cb-e8f6-4804-b0ca-e058da7a3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social Security Number - There are differences based on A, B, and C\n",
    "df['CPR-nummer'] = df['Tekst'].str.extract('CPR-nr\\. (\\d{10})')\n",
    "\n",
    "# \"Hvad fejler du?\"\n",
    "df['Hvad fejler du'] = df['Tekst'].str.extract(r'Hvad fejler du\\?\\s*([^.\\n]+)')\n",
    "\n",
    "# \"Uddyb kort og præcist...\"\n",
    "pattern = r'Uddyb kort og præcist, hvilken sygdom der er årsag til dit fravær:(.*?)\\n'\n",
    "\n",
    "# Illness \n",
    "df['Sygdoms årsag'] = df['Tekst'].str.extract(pattern)\n",
    "\n",
    "# Arbejdsskadestyrelsen\n",
    "pattern = r'Er arbejdsskaden anmeldt til Arbejdsskadestyrelsen\\? (\\w+)'\n",
    "\n",
    "# regex pattern to extract if the injury has been reported\n",
    "df['Arbejdsskaden anmeldt'] = df['Tekst'].str.extract(pattern)\n",
    "\n",
    "# Extract previous illness data using different patterns\n",
    "df['Syg1'] = df['Tekst'].str.extract(r'Har du tidligere været sygemeldt af[\\s\\S]*?(Ja|Nej|ja|nej)[\\s\\S]*?samme årsag\\?')\n",
    "df['Syg2'] = df['Tekst'].str.extract(r'Har du tidligere været sygemeldt af samme årsag\\?\\s*(Ja|Nej|ja|nej)')\n",
    "\n",
    "# A new regex pattern to handle line breaks in the question\n",
    "df['Syg3'] = df['Tekst'].str.extract(r'Har du tidligere været[\\s\\S]*?(Ja|Nej|ja|nej)[\\s\\S]*?samme årsag\\?')\n",
    "\n",
    "# Combine the results from the different patterns into one column\n",
    "df['Syg af samme årsag'] = df['Syg1'].combine_first(df['Syg2']).combine_first(df['Syg3'])\n",
    "\n",
    "# Remove temporary columns used for intermediate results\n",
    "df.drop(['Syg1', 'Syg2', 'Syg3'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f1790-9102-475e-8242-65ff0c9066d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# life-threatening\n",
    "df['Livstruende sygdom'] = df['Tekst'].str.extract(r'Er din sygdom livstruende\\?\\s*(\\w+)')\n",
    "\n",
    "# Work-related injury\n",
    "df['Arbejdsskade'] = df['Tekst'].str.extract(r'(?:Skyldes\\s+dit\\s+fravær\\s+en\\s+arbejdsskade\\?|Forventer\\s+du\\s+at\\s+vende\\s+tilbage)\\s*[\\s\\S]*?\\s*(ja|nej|Ja|Nej)')\n",
    "\n",
    "# Arbejdsskadestyrelsen\n",
    "pattern = r'Er arbejdsskaden anmeldt til Arbejdsskadestyrelsen\\? (\\w+)'\n",
    "df['Arbejdsskaden anmeldt'] = df['Tekst'].str.extract(pattern)\n",
    "\n",
    "# Accident/injury/assault\n",
    "df['Ulykke/tilskadekomst/overfald'] = df['Tekst'].str.extract(r'Skyldes\\s+dit\\s+fravær[\\s\\S]+?(?:ulykke|tilskadekomst|overfald)[\\s\\S]+?\\?\\s*\\(\\s*personskade\\s*\\)[\\s\\S]+?(Ja|Nej|ja|nej)')\n",
    "\n",
    "# Job position\n",
    "df['Stilling'] = df['Tekst'].str.extract(r'Din stilling:\\s*(.+?)(?=\\n|[A-Z]|$)')\n",
    "\n",
    "# Education information\n",
    "pattern = r'Din uddannelse: ([^\\n]+)'\n",
    "df[['Uddannelse']] = df['Tekst'].str.extract(pattern)\n",
    "\n",
    "# Axpected recovery date\n",
    "pattern = r'(\\d{1,2}\\.\\s+\\w+\\s+\\d{4})'\n",
    "df['Forventet raskmeldingsdato'] = df['Tekst'].str.extract(pattern)\n",
    "df['Forventet raskmeldingsdato'] = df['Forventet raskmeldingsdato'].str.replace('\\n', ' ').str.strip()\n",
    "\n",
    "# Extract if the employee expects to return to their workplace\n",
    "def extract_answer(text, question_start):\n",
    "    lines = text.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if question_start in line:\n",
    "            # Answer on the same line\n",
    "            if \"Ja\" in line or \"Nej\" in line:\n",
    "                return re.search(r'(Ja|Nej)', line).group(1)\n",
    "            # Answer on the next line\n",
    "            elif i + 1 < len(lines) and (lines[i + 1].strip() == \"Ja\" or lines[i + 1].strip() == \"Nej\"):\n",
    "                return lines[i + 1].strip()\n",
    "    return None\n",
    "\n",
    "df['Tilbage til arbejdspladsen'] = df['Tekst'].apply(lambda x: extract_answer(x, \"Forventer du at vende tilbage\"))\n",
    "\n",
    "# Undergoing treatment for their illness\n",
    "df['Behandling'] = df['Tekst'].str.extract(r'Er du i behandling for din sygdom\\?\\s*(\\w+)')\n",
    "\n",
    "# Awaiting surgery\n",
    "df['Afventer operation'] = df['Tekst'].str.extract(r'Afventer du en operation\\?\\s*(\\w+)')\n",
    "\n",
    "# Person's work before they were signed off\n",
    "def find_answers(text):\n",
    "    answer_matches = re.findall(r'Har du, eller er du ved at få en.*?(ja|nej)\\b', text, re.IGNORECASE | re.DOTALL)\n",
    "    if answer_matches:\n",
    "        return [match.lower() for match in answer_matches]  # Returns \"ja\" or \"nej\"\n",
    "    return []\n",
    "\n",
    "# Apply the function to find the answers and remove empty lists\n",
    "df['Påvirker sygdom arbejdet'] = df['Tekst'].apply(lambda x: find_answers(x))\n",
    "df['Påvirker sygdom arbejdet'] = df['Påvirker sygdom arbejdet'].apply(lambda x: x[0] if x else None)\n",
    "\n",
    "# Amployer's response\n",
    "df['Din arbejdsgivers svar:'] = df['Tekst'].str.extract(r'Din arbejdsgivers svar:\\s*(.+)')\n",
    "\n",
    "# Citizen's response\n",
    "df['Dit svar:'] = df['Tekst'].str.extract(r'Dit svar:\\s*(.+)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1317503-83f7-42e2-ac90-45abb5bff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illness affected your work? Second responses from the employer and citizen\n",
    "\n",
    "def find_second_occurrence(text, pattern):\n",
    "    matches = re.finditer(pattern, text)\n",
    "    for i, match in enumerate(matches):\n",
    "        if i == 1:  # Second occurrence (indexing starts at 0)\n",
    "            return match.group(1)\n",
    "    return None  # Return None if there is no second occurrence\n",
    "\n",
    "# Second occurrence of the employer's response\n",
    "pattern = r'Din arbejdsgivers svar:\\s*(.+)'\n",
    "df['Din arbejdsgivers andet svar:'] = df['Tekst'].apply(lambda x: find_second_occurrence(x, pattern))\n",
    "\n",
    "# Second occurrence of the citizen's response\n",
    "pattern = r'Dit svar:\\s*(.+)'\n",
    "df['Dit andet svar:'] = df['Tekst'].apply(lambda x: find_second_occurrence(x, pattern))\n",
    "\n",
    "# Extract third responses from the employer and citizen\n",
    "\n",
    "def find_third_occurrence(text, pattern):\n",
    "    matches = re.finditer(pattern, text)\n",
    "    for i, match in enumerate(matches):\n",
    "        if i == 2:  # Third occurrence (indexing starts at 0)\n",
    "            return match.group(1)\n",
    "    return None  # Return None if there is no third occurrence\n",
    "\n",
    "# Third occurrence of the employer's response\n",
    "pattern = r'Din arbejdsgivers svar:\\s*(.+)'\n",
    "df['Din arbejdsgivers tredje svar:'] = df['Tekst'].apply(lambda x: find_third_occurrence(x, pattern))\n",
    "\n",
    "# Third occurrence of the citizen's response\n",
    "pattern = r'Dit svar:\\s*(.+)'\n",
    "df['Dit tredje svar:'] = df['Tekst'].apply(lambda x: find_third_occurrence(x, pattern))\n",
    "\n",
    "# Plan for returning to work? \n",
    "\n",
    "def find_answers(text):\n",
    "    # Find \"yes\" or \"no\" answers related to the question\n",
    "    answer_matches = re.findall(r'Har du og din arbejdsgiver.*?(ja|nej)\\b', text, re.IGNORECASE | re.DOTALL)\n",
    "    if answer_matches:\n",
    "        return [match.lower() for match in answer_matches]  # Return answers in lowercase\n",
    "    return []\n",
    "\n",
    "# Function to the DataFrame and remove empty lists\n",
    "df['Tilbagevenden til arbejdet'] = df['Tekst'].apply(lambda x: find_answers(x))\n",
    "df['Tilbagevenden til arbejdet'] = df['Tilbagevenden til arbejdet'].apply(lambda x: x[0] if x else None)\n",
    "\n",
    "# Do you have, or are you in the process of obtaining a medical certificate for your employer?\n",
    "\n",
    "def find_answers(text):\n",
    "    # Find \"yes\" or \"no\" answers related to the question\n",
    "    answer_matches = re.findall(r'Har du, eller er du ved at få en.*?(ja|nej)\\b', text, re.IGNORECASE | re.DOTALL)\n",
    "    if answer_matches:\n",
    "        return [match.lower() for match in answer_matches]  # Return answers in lowercase\n",
    "    return []\n",
    "\n",
    "# Function to the DataFrame and remove empty lists\n",
    "df['Lægeerklæring'] = df['Tekst'].apply(lambda x: find_answers(x))\n",
    "df['Lægeerklæring'] = df['Lægeerklæring'].apply(lambda x: x[0] if x else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82af0748-e376-4abc-a322-ddaae160430a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Minor data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74c14d-4e82-4218-a3f4-1af9cff5bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Unwanted Columns\n",
    "df = df.drop(['PDF Filnavn', 'Tekst'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8bece-22d7-4154-a655-3dae4bf546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows where the column has NaN values\n",
    "df = df.dropna(subset=['Arbejdsskade', 'Arbejdsskade', 'Ulykke/tilskadekomst/overfald', 'Tilbagevenden til arbejdet', \n",
    "             'Påvirker sygdom arbejdet', 'Tilbage til arbejdspladsen', 'Lægeerklæring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdd51f-c8eb-4ef6-9174-7f236e39291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates, keeping only the first occurrence of each CPR number\n",
    "df = df.drop_duplicates(subset='CPR-nummer', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19255bf-5d20-4a54-9d4a-1a0196b3c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'Arbejdsskaden anmeldt' to 'Nej' if 'Arbejdsskade' is 'Nej' and 'Arbejdsskaden anmeldt' is NaN\n",
    "df.loc[(df['Arbejdsskade'] == 'Nej') & (df['Arbejdsskaden anmeldt'].isna()), 'Arbejdsskaden anmeldt'] = 'Nej'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db89b9e-48ef-4036-abde-0164c5a3a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the scraped data with the main data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e48e8-1907-4a84-9bd5-90c1b840c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\...', dtype={'CPR-nummer': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b576385-4f53-44b1-9f84-714be55cf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a right join on 'CPR-nummer' to merge \n",
    "merged_df = df.merge(csv_df, on='CPR-nummer', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7166f6-742b-4fac-998f-23fcb4d03d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged DataFrame to a CSV file named 'commune01.csv', excluding the index\n",
    "merged_df.to_csv('commune01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
